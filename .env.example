# ============================================================================
# Deep-Tutor Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your API keys and settings.
# All API keys should be kept confidential and never committed to version control.
# You can adjust the max_token parameters in DeepTutor/config/agents.yaml.
# ============================================================================

# ============================================================================
# Server Configuration
# ============================================================================
# Configure the server ports and API URL for remote access.

# Backend API port (default: 8001)
# BACKEND_PORT=8001

# Frontend web port (default: 3782)
# FRONTEND_PORT=3782

# Frontend API Base URL (for remote/LAN access)
# Set this when accessing DeepTutor from another device on your network.
# Example: If your server IP is 192.168.1.100, set:
#   NEXT_PUBLIC_API_BASE=http://192.168.1.100:8001
# If not set, defaults to http://localhost:8001 (only works on the local machine)

# NEXT_PUBLIC_API_BASE=http://your-server-ip:8001 (optional)

# ============================================================================
# LLM Deployment Mode Configuration
# ============================================================================
# Control how DeepTutor selects LLM providers.
#
# Options:
#   - hybrid (default): Use both API and Local providers. Active provider takes priority.
#   - api: Only use cloud API providers (OpenAI, Anthropic, DeepSeek, etc.)
#   - local: Only use local/self-hosted providers (Ollama, LM Studio, vLLM, etc.)
#
# In hybrid mode, you can add both API and local providers via the Settings UI,
# and switch between them by setting one as "active".

LLM_MODE=hybrid

# ============================================================================
# LLM (Large Language Model) Configuration
# ============================================================================
# Configure the main AI model used for reasoning, generation, and conversation.
# Supports OpenAI-compatible APIs (OpenAI, Azure OpenAI, DeepSeek, Qwen, etc.)
# and local servers (Ollama, LM Studio, vLLM, llama.cpp).
#
# Note: These environment variables serve as the default/fallback configuration.
# You can also add providers via the Settings UI, which takes priority when active.

# LLM service provider type
# Options: openai, azure_openai, ollama, anthropic
LLM_BINDING=openai

# Model name for the LLM
# Cloud examples: gpt-4o, gpt-4o-mini, deepseek-chat, claude-3-5-sonnet-20241022
# Local examples: llama3.2, qwen2.5, mistral-nemo, deepseek-r1
LLM_MODEL=

# LLM API endpoint URL
# Cloud examples:
#   - OpenAI: https://api.openai.com/v1
#   - DeepSeek: https://api.deepseek.com
#   - Anthropic: https://api.anthropic.com/v1
# Local examples:
#   - Ollama: http://localhost:11434/v1
#   - LM Studio: http://localhost:1234/v1
#   - vLLM: http://localhost:8000/v1
#   - llama.cpp: http://localhost:8080/v1
LLM_HOST=

# LLM API authentication key
# Required for cloud APIs, optional for local deployment
# For Ollama, you can use any string (e.g., "ollama")
LLM_API_KEY=

# Disable SSL certificate verification (set 'true' for self-signed certificates)
DISABLE_SSL_VERIFY=false

# ============================================================================
# Embedding Model Configuration
# ============================================================================
# Configure the text embedding model used for semantic search and RAG.
# Required for knowledge base functionality.

# Embedding service provider type
# Options: openai, azure_openai, ollama, lollms
EMBEDDING_BINDING=openai

# Embedding model name
# Cloud examples: text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002
# Local examples (Ollama): nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=text-embedding-3-large

# Embedding vector dimension
# text-embedding-3-large: 3072
# text-embedding-3-small: 1536
# nomic-embed-text: 768
# mxbai-embed-large: 1024
EMBEDDING_DIMENSION=3072

# Embedding API endpoint URL
# Cloud: https://api.openai.com/v1
# Local (Ollama): http://localhost:11434
EMBEDDING_HOST=

# Embedding API authentication key
# Required for cloud providers, not needed for Ollama
EMBEDDING_API_KEY=

# ============================================================================
# TTS (Text-to-Speech) Configuration
# ============================================================================
# Configure voice synthesis for the Co-Writer (Interactive IdeaGen) narration feature.
# Supports CosyVoice (local, free, recommended) and OpenAI TTS (paid, fallback).
# Also remember to choose a voice in DeepTutor/config/main.yaml.

# TTS Provider Selection (true = CosyVoice, false = OpenAI TTS)
USE_COSYVOICE=true

# CosyVoice Configuration (local TTS, free)
# Version selection: 1.0, 2.0, 3.0 (recommended)
COSYVOICE_VERSION=3.0

# OpenAI TTS Configuration (paid, fallback when USE_COSYVOICE=false)
# TTS model name (e.g., tts-1, tts-1-hd)
TTS_MODEL=

# TTS API endpoint URL (e.g., https://api.openai.com/v1)
TTS_URL=

# Inference mode: instruct (recommended), zero_shot, sft, cross_lingual
COSYVOICE_MODE=instruct

# Conda environment name
COSYVOICE_CONDA_ENV=DeepTutor-env-3.11

# Default voice (CosyVoice options: 中文女, 中文男, 英文女, etc.)
TTS_VOICE=中文女

# Optional: Custom model path (auto-detected if not specified)
# ModelScope downloads to: ~/.cache/modelscope/hub/FunAudioLLM/Fun-CosyVoice3-0.5B-YYYYMMDD
# COSYVOICE_MODEL_DIR=/Users/berton/.cache/modelscope/hub/FunAudioLLM/Fun-CosyVoice3-0.5B-2512

# OpenAI TTS Configuration (fallback, paid)
# Uncomment these if using OpenAI TTS instead:
# TTS_MODEL=tts-1
# TTS_URL=https://api.openai.com/v1
# TTS_API_KEY=your_OpenAI_API_key

# ============================================================================
# Web Search Configuration
# ============================================================================
# Configure external search APIs for research features.
# Choose ONE of the following:

# Option 1: Perplexity AI (General-purpose search)
# Get your API key at: https://www.perplexity.ai/settings/api
# PERPLEXITY_API_KEY=

# Option 2: Exa AI (Optimized for research, recommended)
# Get your API key at: https://dashboard.exa.ai/api-keys
# Free tier: 1000 searches/month
EXA_API_KEY=

# Note: If both are configured, Exa AI will be used by default

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level for RAG tool module
# Options: DEBUG, INFO, WARNING, ERROR
RAG_TOOL_MODULE_LOG_LEVEL=INFO
