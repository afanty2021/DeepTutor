# ============================================================================
# Deep-Tutor Environment Configuration
# Copy this file to .env and fill in your API keys and settings.
# All API keys should be kept confidential and never committed to version control.
# You can adjust the max_token parameters in DeepTutor\config\agents.yaml.
# ============================================================================

# ============================================================================
# LLM (Large Language Model) Configuration
# ============================================================================
# Configure the main AI model used for reasoning, generation, and conversation.
# Supports OpenAI-compatible APIs (OpenAI, Azure OpenAI, DeepSeek, Qwen, etc.)

# LLM service provider type
# Options: openai, azure_openai, ollama, lollms
LLM_BINDING=openai

# Model name for the LLM
LLM_MODEL=

# LLM API endpoint URL
LLM_BINDING_HOST=

# LLM API authentication key
LLM_BINDING_API_KEY=

# Disable SSL certificate verification (set 'true' for self-signed certificates)
DISABLE_SSL_VERIFY=false

# ============================================================================
# Embedding Model Configuration
# ============================================================================
# Configure the text embedding model used for semantic search and RAG.
# Required for knowledge base functionality.

# Embedding service provider type
# Options: openai, azure_openai, ollama, lollms
EMBEDDING_BINDING=openai

# Embedding model name
# Examples: text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-large

# Embedding vector dimension
EMBEDDING_DIM=3072

# Embedding API endpoint URL
EMBEDDING_BINDING_HOST=

# Embedding API authentication key
EMBEDDING_BINDING_API_KEY=

# ============================================================================
# TTS (Text-to-Speech) Configuration
# ============================================================================
# Configure voice synthesis for the Co-Writer (Interactive IdeaGen) narration feature.
# Supports CosyVoice (local, free, recommended) and OpenAI TTS (paid, fallback).
# Also remember to choose a voice in config/main.yaml.

# TTS Provider Selection (true = CosyVoice, false = OpenAI TTS)
USE_COSYVOICE=true

# CosyVoice Configuration (local TTS, free)
# Version selection: 1.0, 2.0, 3.0 (recommended)
COSYVOICE_VERSION=3.0

# Inference mode: instruct (recommended), zero_shot, sft, cross_lingual
COSYVOICE_MODE=instruct

# Conda environment name
COSYVOICE_CONDA_ENV=DeepTutor-env-3.11

# Default voice (CosyVoice options: 中文女, 中文男, 英文女, etc.)
TTS_VOICE=中文女

# Optional: Custom model path (auto-detected if not specified)
# ModelScope downloads to: ~/.cache/modelscope/hub/FunAudioLLM/Fun-CosyVoice3-0.5B-YYYYMMDD
# COSYVOICE_MODEL_DIR=/Users/berton/.cache/modelscope/hub/FunAudioLLM/Fun-CosyVoice3-0.5B-2512

# OpenAI TTS Configuration (fallback, paid)
# Uncomment these if using OpenAI TTS instead:
# TTS_MODEL=tts-1
# TTS_URL=https://api.openai.com/v1
# TTS_API_KEY=your_OpenAI_API_key

# ============================================================================
# Web Search Configuration
# ============================================================================
# Configure external search APIs for research features.
# Choose ONE of the following:

# Option 1: Perplexity AI (General-purpose search)
# Get your API key at: https://www.perplexity.ai/settings/api
# PERPLEXITY_API_KEY=

# Option 2: Exa AI (Optimized for research, recommended)
# Get your API key at: https://dashboard.exa.ai/api-keys
# Free tier: 1000 searches/month
EXA_API_KEY=

# Note: If both are configured, Exa AI will be used by default

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level for RAG tool module
# Options: DEBUG, INFO, WARNING, ERROR
RAG_TOOL_MODULE_LOG_LEVEL=INFO
