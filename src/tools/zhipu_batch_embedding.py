#!/usr/bin/env python
"""
æ™ºè°± AI Batch API Embedding å®¢æˆ·ç«¯

æä¾›æ‰¹é‡ Embedding åŠŸèƒ½ï¼Œä½¿ç”¨æ™ºè°± Batch APIï¼š
- æ— å¹¶å‘é™åˆ¶ï¼ˆEmbedding-3 é˜Ÿåˆ— 200ä¸‡æ¬¡ï¼‰
- 50% æˆæœ¬èŠ‚çœ
- é€‚åˆå¤§è§„æ¨¡æ•°æ®å¤„ç†

ä½¿ç”¨æ–¹å¼ï¼š
    from src.tools.zhipu_batch_embedding import BatchEmbeddingClient

    client = BatchEmbeddingClient(api_key="your-api-key")
    embeddings = client.embed_texts(
        texts=["æ–‡æœ¬1", "æ–‡æœ¬2", ...],
        model="embedding-3"
    )
"""

import json
import os
import time
import tempfile
from pathlib import Path
from typing import Any

try:
    from zhipuai import ZhipuAIClient
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… zhipuai SDKï¼Œæä¾›é”™è¯¯æç¤º
    ZhipuAIClient = None
    import warnings
    warnings.warn(
        "zhipuai SDK æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install zhipuai",
        ImportWarning,
        stacklevel=2
    )


class BatchEmbeddingClient:
    """
    æ™ºè°± AI Batch Embedding å®¢æˆ·ç«¯

    ç‰¹æ€§ï¼š
    - è‡ªåŠ¨æ‰¹é‡å¤„ç†æ–‡æœ¬
    - æ”¯æŒè¶…è¿‡ 10,000 æ¡çš„æ‰¹é‡è¯·æ±‚
    - è‡ªåŠ¨åˆ†ç‰‡ä¸Šä¼ 
    - ç»“æœç¼“å­˜å’Œé”™è¯¯é‡è¯•
    """

    # Batch API é™åˆ¶
    MAX_REQUESTS_PER_FILE = 10000  # Embedding æ¨¡å‹é™åˆ¶
    MAX_FILE_SIZE_MB = 100
    DEFAULT_ENDPOINT = "/v4/embeddings"

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://open.bigmodel.cn/api/paas/v4/",
        batch_threshold: int = 100,
    ):
        """
        åˆå§‹åŒ– Batch Embedding å®¢æˆ·ç«¯

        Args:
            api_key: æ™ºè°± AI API Key
            base_url: API åŸºç¡€ URL
            batch_threshold: æ‰¹é‡é˜ˆå€¼ï¼ˆè¾¾åˆ°æ­¤æ•°é‡æ—¶è§¦å‘ Batch APIï¼‰
        """
        if ZhipuAIClient is None:
            raise ImportError(
                "è¯·å…ˆå®‰è£… zhipuai SDK: pip install zhipuai"
            )

        self.client = ZhipuAIClient(
            api_key=api_key,
            base_url=base_url
        )
        self.batch_threshold = batch_threshold

    def embed_texts(
        self,
        texts: list[str],
        model: str = "embedding-3",
        auto_batch: bool = True,
    ) -> list[list[float]]:
        """
        å¯¹æ–‡æœ¬åˆ—è¡¨è¿›è¡Œ Embedding

        Args:
            texts: å¾… Embedding çš„æ–‡æœ¬åˆ—è¡¨
            model: Embedding æ¨¡å‹åç§°
            auto_batch: æ˜¯å¦è‡ªåŠ¨ä½¿ç”¨ Batch APIï¼ˆè¾¾åˆ°é˜ˆå€¼æ—¶ï¼‰

        Returns:
            Embedding å‘é‡åˆ—è¡¨

        Raises:
            ValueError: å¦‚æœæ–‡æœ¬åˆ—è¡¨ä¸ºç©º
            RuntimeError: å¦‚æœ Batch ä»»åŠ¡å¤±è´¥
        """
        if not texts:
            raise ValueError("æ–‡æœ¬åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # å¦‚æœæ–‡æœ¬æ•°é‡è¾ƒå°‘ï¼Œç›´æ¥ä½¿ç”¨å®æ—¶ API
        if len(texts) < self.batch_threshold or not auto_batch:
            return self._embed_realtime(texts, model)

        # ä½¿ç”¨ Batch API å¤„ç†å¤§é‡æ–‡æœ¬
        return self._embed_batch(texts, model)

    def _embed_realtime(
        self,
        texts: list[str],
        model: str,
    ) -> list[list[float]]:
        """
        ä½¿ç”¨å®æ—¶ API è¿›è¡Œ Embeddingï¼ˆå°æ‰¹é‡æˆ–å¿«é€Ÿå“åº”ï¼‰

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°

        Returns:
            å‘é‡åˆ—è¡¨
        """
        embeddings = []

        # æ™ºè°± API æ”¯æŒæ‰¹é‡è¯·æ±‚ï¼ˆæœ€å¤š 64 æ¡ï¼‰
        batch_size = 64

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]

            try:
                response = self.client.embeddings.create(
                    model=model,
                    input=batch,
                )

                # æå–å‘é‡
                batch_embeddings = [item.embedding for item in response.data]
                embeddings.extend(batch_embeddings)

            except Exception as e:
                raise RuntimeError(f"å®æ—¶ API Embedding å¤±è´¥: {e}") from e

        return embeddings

    def _embed_batch(
        self,
        texts: list[str],
        model: str,
    ) -> list[list[float]]:
        """
        ä½¿ç”¨ Batch API è¿›è¡Œ Embeddingï¼ˆå¤§æ‰¹é‡ï¼‰

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°

        Returns:
            å‘é‡åˆ—è¡¨
        """
        # å¦‚æœæ–‡æœ¬æ•°é‡è¶…è¿‡å•æ–‡ä»¶é™åˆ¶ï¼Œåˆ†ç‰‡å¤„ç†
        if len(texts) > self.MAX_REQUESTS_PER_FILE:
            all_embeddings = []
            for i in range(0, len(texts), self.MAX_REQUESTS_PER_FILE):
                batch_texts = texts[i:i + self.MAX_REQUESTS_PER_FILE]
                batch_embeddings = self._process_single_batch(
                    batch_texts,
                    model
                )
                all_embeddings.extend(batch_embeddings)
            return all_embeddings
        else:
            return self._process_single_batch(texts, model)

    def _process_single_batch(
        self,
        texts: list[str],
        model: str,
    ) -> list[list[float]]:
        """
        å¤„ç†å•ä¸ª Batch ä»»åŠ¡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°

        Returns:
            å‘é‡åˆ—è¡¨
        """
        # 1. åˆ›å»º .jsonl æ–‡ä»¶
        jsonl_path = self._create_jsonl_file(texts, model)

        try:
            # 2. ä¸Šä¼ æ–‡ä»¶
            file_object = self.client.files.create(
                file=open(jsonl_path, "rb"),
                purpose="batch"
            )

            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_object.id}")

            # 3. åˆ›å»º Batch ä»»åŠ¡
            batch = self.client.batches.create(
                input_file_id=file_object.id,
                endpoint=self.DEFAULT_ENDPOINT,
                auto_delete_input_file=True,
                metadata={
                    "model": model,
                    "text_count": len(texts),
                }
            )

            print(f"âœ… Batch ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {batch.id}")
            print(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ... (é¢„è®¡24å°æ—¶å†…)")

            # 4. ç›‘æ§ä»»åŠ¡çŠ¶æ€
            batch_status = self._wait_for_completion(batch.id)

            # 5. ä¸‹è½½ç»“æœ
            embeddings = self._download_results(batch_status)

            return embeddings

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(jsonl_path):
                os.remove(jsonl_path)

    def _create_jsonl_file(
        self,
        texts: list[str],
        model: str,
    ) -> str:
        """
        åˆ›å»º Batch API æ‰€éœ€çš„ .jsonl æ–‡ä»¶

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°

        Returns:
            .jsonl æ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        fd, jsonl_path = tempfile.mkstemp(
            suffix=".jsonl",
            prefix="zhipu_batch_"
        )
        os.close(fd)

        # å†™å…¥ JSONL æ ¼å¼
        with open(jsonl_path, "w", encoding="utf-8") as f:
            for idx, text in enumerate(texts, 1):
                request = {
                    "custom_id": f"request-{idx}",
                    "method": "POST",
                    "url": self.DEFAULT_ENDPOINT,
                    "body": {
                        "model": model,
                        "input": text,
                    }
                }
                f.write(json.dumps(request, ensure_ascii=False) + "\n")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size_mb = os.path.getsize(jsonl_path) / (1024 * 1024)
        if file_size_mb > self.MAX_FILE_SIZE_MB:
            os.remove(jsonl_path)
            raise ValueError(
                f"æ–‡ä»¶å¤§å° ({file_size_mb:.1f}MB) è¶…è¿‡é™åˆ¶ "
                f"({self.MAX_FILE_SIZE_MB}MB)"
            )

        return jsonl_path

    def _wait_for_completion(
        self,
        batch_id: str,
        check_interval: int = 60,
    ) -> Any:
        """
        ç­‰å¾… Batch ä»»åŠ¡å®Œæˆ

        Args:
            batch_id: Batch ä»»åŠ¡ ID
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            å®Œæˆçš„ Batch å¯¹è±¡
        """
        print(f"â³ å¼€å§‹ç›‘æ§ä»»åŠ¡çŠ¶æ€ (æ¯ {check_interval} ç§’æ£€æŸ¥ä¸€æ¬¡)...")

        while True:
            batch_status = self.client.batches.retrieve(batch_id)

            status = batch_status.status
            print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {status}")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if status == "completed":
                print("âœ… ä»»åŠ¡å®Œæˆï¼")
                return batch_status
            elif status in ["failed", "expired", "cancelled"]:
                error_msg = f"ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€: {status}"
                if hasattr(batch_status, "error_file_id") and batch_status.error_file_id:
                    error_msg += f" (é”™è¯¯æ–‡ä»¶: {batch_status.error_file_id})"
                raise RuntimeError(error_msg)

            # ç­‰å¾…åå†æ¬¡æ£€æŸ¥
            time.sleep(check_interval)

    def _download_results(
        self,
        batch_status: Any,
    ) -> list[list[float]]:
        """
        ä¸‹è½½å¹¶è§£æ Batch ç»“æœ

        Args:
            batch_status: å®Œæˆçš„ Batch å¯¹è±¡

        Returns:
            å‘é‡åˆ—è¡¨
        """
        # ä¸‹è½½æˆåŠŸç»“æœ
        if hasattr(batch_status, "output_file_id") and batch_status.output_file_id:
            result_content = self.client.files.content(batch_status.output_file_id)
            result_text = result_content.content.decode("utf-8")

            # è§£æç»“æœ
            embeddings = self._parse_batch_results(result_text)
            print(f"âœ… æˆåŠŸè·å– {len(embeddings)} ä¸ªå‘é‡")

            return embeddings
        else:
            raise RuntimeError("Batch ä»»åŠ¡æœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶")

    def _parse_batch_results(
        self,
        result_text: str,
    ) -> list[list[float]]:
        """
        è§£æ Batch API è¿”å›çš„ JSONL ç»“æœ

        Args:
            result_text: JSONL æ ¼å¼çš„ç»“æœæ–‡æœ¬

        Returns:
            å‘é‡åˆ—è¡¨ï¼ˆæŒ‰ custom_id æ’åºï¼‰
        """
        results = []

        for line in result_text.strip().split("\n"):
            if not line:
                continue

            try:
                result = json.loads(line)

                # æ£€æŸ¥çŠ¶æ€ç 
                if (
                    hasattr(result, "response")
                    and hasattr(result.response, "status_code")
                    and result.response.status_code == 200
                ):
                    # æå–å‘é‡
                    embedding = result.response.body.data[0].embedding
                    results.append({
                        "custom_id": result.custom_id,
                        "embedding": embedding,
                    })
                else:
                    print(f"âš ï¸ è¯·æ±‚ {result.custom_id} å¤±è´¥")

            except (json.JSONDecodeError, KeyError, AttributeError) as e:
                print(f"âš ï¸ è§£æç»“æœè¡Œå¤±è´¥: {e}")
                continue

        # æŒ‰ custom_id æ’åºä»¥ä¿æŒåŸå§‹é¡ºåº
        results.sort(key=lambda x: x["custom_id"])
        return [r["embedding"] for r in results]


def embed_texts_batch(
    texts: list[str],
    api_key: str,
    model: str = "embedding-3",
    batch_threshold: int = 100,
) -> list[list[float]]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡ Embedding æ–‡æœ¬

    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
        api_key: æ™ºè°± AI API Key
        model: Embedding æ¨¡å‹åç§°
        batch_threshold: æ‰¹é‡é˜ˆå€¼

    Returns:
        å‘é‡åˆ—è¡¨

    Example:
        >>> embeddings = embed_texts_batch(
        ...     texts=["ä½ å¥½", "ä¸–ç•Œ"],
        ...     api_key="your-api-key",
        ...     model="embedding-3"
        ... )
    """
    client = BatchEmbeddingClient(
        api_key=api_key,
        batch_threshold=batch_threshold,
    )
    return client.embed_texts(texts, model=model)


__all__ = [
    "BatchEmbeddingClient",
    "embed_texts_batch",
]
